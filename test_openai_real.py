#!/usr/bin/env python3
"""
Test OpenAI Real LLM Integration
Tests the complete system with real OpenAI LLM instead of mock.
"""

import asyncio
import sys
import os

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.graph.credit_card_graph import create_credit_card_graph, create_initial_state
from src.tools.mock_tools import MockLLMTool, MockPolicyTool


async def test_openai_llm_tool():
    """Test the OpenAI LLM tool directly."""
    print("üß™ Testing OpenAI LLM Tool...")
    
    try:
        # Create LLM tool with OpenAI (will fallback to mock if no API key)
        llm_tool = MockLLMTool(use_openai=True)
        
        if llm_tool.use_openai:
            print("   ‚úÖ OpenAI LLM mode enabled")
            
            # Test NLU extraction
            schema = {
                "type": "object",
                "properties": {
                    "intent": {"type": "string"},
                    "goals": {"type": "array", "items": {"type": "string"}},
                    "jurisdiction": {"type": "string"},
                    "risk_tolerance": {"type": "string"}
                }
            }
            
            test_query = "I want a travel credit card for airline miles and international travel"
            print(f"   ‚úÖ Testing extraction with: {test_query}")
            
            result = await llm_tool.nlu_extract(test_query, schema)
            print(f"   ‚úÖ Extraction result: {result}")
            
            # Test response generation
            prompt = "Explain why this card is good for travel"
            response = await llm_tool.generate_response(prompt, {"card_type": "travel"})
            print(f"   ‚úÖ Generated response: {response[:100]}...")
            
        else:
            print("   ‚ö†Ô∏è OpenAI API key not found, using mock mode")
            print("   üí° Set OPENAI_API_KEY environment variable to test real LLM")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå OpenAI LLM tool test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_openai_graph_integration():
    """Test the complete graph with OpenAI LLM."""
    print("\nüß™ Testing OpenAI Graph Integration...")
    
    try:
        # Create tools with OpenAI LLM
        llm_tool = MockLLMTool(use_openai=True)
        policy_tool = MockPolicyTool()
        
        if not llm_tool.use_openai:
            print("   ‚ö†Ô∏è Skipping OpenAI test - no API key available")
            return True
        
        # Create and test graph
        graph = create_credit_card_graph(llm_tool, policy_tool)
        print("   ‚úÖ Graph created with OpenAI LLM")
        
        # Test with a travel request
        initial_state = create_initial_state(
            "I need a credit card for business travel with lounge access and travel insurance"
        )
        
        print(f"   ‚úÖ Testing with query: {initial_state.user_query}")
        
        # Execute the graph
        result = await graph.ainvoke(initial_state)
        
        print(f"   ‚úÖ Graph execution completed")
        print(f"   ‚úÖ Final state keys: {list(result.keys())}")
        
        # Check results
        if 'completed_nodes' in result:
            completed_nodes = result['completed_nodes']
            print(f"   ‚úÖ Completed nodes: {completed_nodes}")
        
        if 'manager_results' in result and result['manager_results']:
            print(f"   ‚úÖ Manager results available")
            for manager_type, manager_result in result['manager_results'].items():
                print(f"   ‚úÖ {manager_type}: {len(manager_result.recommendations)} recommendations")
        
        if 'final_recommendations' in result and result['final_recommendations']:
            final_recs = result['final_recommendations']
            print(f"   ‚úÖ Final recommendations available")
            print(f"   ‚úÖ Total cards analyzed: {final_recs.total_cards_analyzed}")
            
            if final_recs.top_recommendation:
                top_rec = final_recs.top_recommendation
                print(f"   ‚úÖ Top recommendation: {top_rec.card_name}")
                print(f"   ‚úÖ Overall score: {top_rec.overall_score:.2f}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå OpenAI graph integration test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_openai_fallback():
    """Test that the system gracefully falls back to mock when OpenAI fails."""
    print("\nüß™ Testing OpenAI Fallback Behavior...")
    
    try:
        # Create LLM tool with OpenAI but simulate failure
        llm_tool = MockLLMTool(use_openai=True)
        
        if not llm_tool.use_openai:
            print("   ‚ö†Ô∏è Skipping fallback test - no API key available")
            return True
        
        # Test with a complex query that might trigger fallback
        schema = {
            "type": "object",
            "properties": {
                "intent": {"type": "string"},
                "goals": {"type": "array", "items": {"type": "string"}},
                "jurisdiction": {"type": "string"}
            }
        }
        
        test_query = "I want a credit card for students with no annual fee and good rewards"
        print(f"   ‚úÖ Testing fallback with: {test_query}")
        
        result = await llm_tool.nlu_extract(test_query, schema)
        print(f"   ‚úÖ Fallback result: {result}")
        
        # Verify fallback worked
        if result.get("goals") and "student" in result["goals"]:
            print("   ‚úÖ Fallback extraction successful")
        else:
            print("   ‚ö†Ô∏è Fallback extraction may not have worked as expected")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå OpenAI fallback test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Run all OpenAI integration tests."""
    print("üöÄ Testing OpenAI Real LLM Integration")
    print("=" * 50)
    
    # Check if OpenAI API key is available
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print(f"‚úÖ OpenAI API key found: {api_key[:10]}...")
    else:
        print("‚ö†Ô∏è No OpenAI API key found - tests will use mock mode")
        print("üí° Set OPENAI_API_KEY environment variable to test real LLM")
    
    print()
    
    # Run tests
    tests = [
        test_openai_llm_tool,
        test_openai_graph_integration,
        test_openai_fallback
    ]
    
    results = []
    for test in tests:
        try:
            result = await test()
            results.append(result)
        except Exception as e:
            print(f"‚ùå Test {test.__name__} failed with exception: {e}")
            results.append(False)
    
    # Summary
    print("\n" + "=" * 50)
    print("üìä Test Results Summary")
    print("=" * 50)
    
    passed = sum(results)
    total = len(results)
    
    print(f"‚úÖ Passed: {passed}/{total}")
    print(f"‚ùå Failed: {total - passed}/{total}")
    
    if passed == total:
        print("üéâ All tests passed! OpenAI integration is working correctly.")
    else:
        print("‚ö†Ô∏è Some tests failed. Check the output above for details.")
    
    return passed == total


if __name__ == "__main__":
    asyncio.run(main())
